import numpy as np
import matplotlib.pyplot as plt
import math
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
import tensorflow as tf
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras import Sequential
from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy, CategoricalCrossentropy
from tensorflow.keras.activations import sigmoid, relu, linear
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)
import copy
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

#Initialise data

df = pd.read_csv(r'C:\Users\joshi\OneDrive\Desktop\ML Projects\Life Expectancy Data.csv')


x_data = df.drop(['Country'], axis=1)

#hot encoding Country 
y_data = pd.get_dummies(df['Country'])

#Fill missing values. For numeric columns, use median; for categorical, use the most frequent value
numeric_features = x_data.select_dtypes(include=['int64', 'float64']).columns
categorical_features = x_data.select_dtypes(include=['object']).columns

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

#preprocess x and y
x_data_processed = preprocessor.fit_transform(x_data)


# Concatenate y_data after preprocessing x_data
combined = pd.concat([df.drop(['Country'], axis=1), pd.get_dummies(df['Country'])], axis=1)

combined = combined.dropna()

x_data = combined.drop(pd.get_dummies(df['Country']).columns, axis=1)
y_data = combined[pd.get_dummies(df['Country']).columns]

# Convert 'developing'/'developed' to 0/1
x_data['Status'] = x_data['Status'].map({'Developing': 0, 'Developed': 1})

#normalizing data
mu = np.mean(x_data,axis=0)
sigma = np.std(x_data,axis=0)


def fnormalize(X,mu,sigma):
    X_norm = np.zeros(X.shape)
    for i in range(X.shape[1]):
        temp_X = X[:,i]
        temp_X = (temp_X-mu[i])/sigma[i]
        X_norm[:,i]=temp_X
    return X_norm


x_data = x_data.to_numpy()  
X_norm = fnormalize(x_data,mu,sigma)


X_train, X_test, y_train, y_test = train_test_split(X_norm, y_data, test_size=0.2, random_state=42)

num_countries = y_data.shape[1]

classifier = DecisionTreeClassifier(random_state=42)

# Train the classifier
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
y_train_pred = classifier.predict(X_train)

accuracy = accuracy_score(y_test, y_pred)
train_accuracy = accuracy_score(y_train,y_train_pred)
print(f"Train Accuracy: {train_accuracy:.2f}")
print(f"Test Accuracy: {accuracy:.2f}")
