import numpy as np
import matplotlib.pyplot as plt
import math
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
import tensorflow as tf
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras import Sequential
from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy, CategoricalCrossentropy
from tensorflow.keras.activations import sigmoid, relu, linear
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)
import copy

#Initialise data

df = pd.read_csv(r'C:\Users\joshi\OneDrive\Desktop\ML Projects\Life Expectancy Data.csv')


x_data = df.drop(['Country'], axis=1)

#hot encoding Country 
y_data = pd.get_dummies(df['Country'])

#Fill missing values. For numeric columns, use median; for categorical, use the most frequent value
numeric_features = x_data.select_dtypes(include=['int64', 'float64']).columns
categorical_features = x_data.select_dtypes(include=['object']).columns

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

#preprocess x and y
x_data_processed = preprocessor.fit_transform(x_data)


# Concatenate y_data after preprocessing x_data
combined = pd.concat([df.drop(['Country'], axis=1), pd.get_dummies(df['Country'])], axis=1)

combined = combined.dropna()

x_data = combined.drop(pd.get_dummies(df['Country']).columns, axis=1)
y_data = combined[pd.get_dummies(df['Country']).columns]

# Convert 'developing'/'developed' to 0/1
x_data['Status'] = x_data['Status'].map({'Developing': 0, 'Developed': 1})

#normalizing data
mu = np.mean(x_data,axis=0)
sigma = np.std(x_data,axis=0)


def fnormalize(X,mu,sigma):
    X_norm = np.zeros(X.shape)
    for i in range(X.shape[1]):
        temp_X = X[:,i]
        temp_X = (temp_X-mu[i])/sigma[i]
        X_norm[:,i]=temp_X
    return X_norm


x_data = x_data.to_numpy()  
X_norm = fnormalize(x_data,mu,sigma)


X_train, X_test, y_train, y_test = train_test_split(X_norm, y_data, test_size=0.2, random_state=42)

num_countries = y_data.shape[1]

tf.random.set_seed(1234)  
model = Sequential(
    [
        tf.keras.Input(shape=(21,)),
        Dense(64, activation='relu', input_shape = (X_train.shape[1],), kernel_regularizer = tf.keras.regularizers.l2(0.0), name = 'layer1'),
        Dense(32, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.0), name = 'layer2'),
        Dense(num_countries, activation='softmax', name = 'layer3')
     ]
)

model.compile(
    loss = tf.keras.losses.CategoricalCrossentropy(),
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy']
)

model.fit(
    X_train,y_train,            
    epochs=100,
)


predictions = model.predict(X_train)
# Convert predictions to class indices
yhat_train = np.argmax(predictions, axis=1)

# Convert y_test to class indices if it's one-hot encoded
y_train_indices = np.argmax(y_train, axis=1)

# Calculate accuracy
accuracy_train = np.mean(yhat_train == y_train_indices)

print(f"Training data accuracy: {accuracy_train * 100:.2f}%")

predictions = model.predict(X_test)
# Convert predictions to class indices
yhat = np.argmax(predictions, axis=1)

# Convert y_test to class indices if it's one-hot encoded
y_test_indices = np.argmax(y_test, axis=1)

# Calculate accuracy
accuracy = np.mean(yhat == y_test_indices)

print(f"Test data accuracy: {accuracy * 100:.2f}%")

# Find mismatch indices
mismatch_indices = np.where(yhat != y_test_indices)[0]

# Assuming y_data is one-hot encoded DataFrame of countries
country_names = y_data.columns
index_to_country = {index: country for index, country in enumerate(country_names)}


# Display mismatches
print("Examples where the model made incorrect predictions: ")
for index in mismatch_indices:
    predicted_index = np.argmax(predictions[index])
    actual_index = np.argmax(y_test.iloc[index])
    
    predicted_country = index_to_country[predicted_index]
    actual_country = index_to_country[actual_index]

    print(f"Index: {index}, Predicted: {predicted_country}, Actual: {actual_country}")

